{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dylan.Tang\\Anaconda3\\envs\\py10\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取CSV檔案\n",
    "df = pd.read_csv('items_colors.csv')\n",
    "# df['match']=df.shape[0]*[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.tensor(df['match'].tolist(), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 將物品和顏色轉換為BERT的輸入\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "item_tokens = tokenizer(df['item'].tolist(), padding=True, truncation=True, max_length=16, return_tensors='pt')\n",
    "color_tokens = tokenizer(df['color'].tolist(), padding=True, truncation=True, max_length=8, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dylan.Tang\\Downloads\\item_color\\train_item_color.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dylan.Tang/Downloads/item_color/train_item_color.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m item_tokens[\u001b[39m0\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\Dylan.Tang\\Anaconda3\\envs\\py10\\lib\\site-packages\\transformers\\tokenization_utils_base.py:240\u001b[0m, in \u001b[0;36mBatchEncoding.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_encodings[item]\n\u001b[0;32m    239\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 240\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[0;32m    241\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndexing with integers (to access backend Encoding for a given batch index) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not available when using Python based tokenizers\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    243\u001b[0m     )\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'"
     ]
    }
   ],
   "source": [
    "item_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 將BERT輸入轉換為BERT輸出\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "item_outputs = bert_model(**item_tokens)[0]\n",
    "color_outputs = bert_model(**color_tokens)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 將BERT輸出作為LSTM輸入\n",
    "class ColorPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorPredictor, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size=768, hidden_size=128, num_layers=2, batch_first=True)\n",
    "        self.fc = nn.Linear(in_features=128, out_features=1)\n",
    "        self.sigmoid = torch.nn.Sigmoid() \n",
    "    def forward(self, item_outputs, color_outputs):\n",
    "        inputs = torch.cat([item_outputs, color_outputs], dim=1)\n",
    "        _, (hn, cn) = self.lstm(inputs)\n",
    "        outputs = self.fc(hn[-1])\n",
    "        # output = self.sigmoid(outputs)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'red'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['color'][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: 0.095\n",
      "Epoch 2 loss: 0.071\n",
      "Epoch 3 loss: 0.072\n",
      "Epoch 4 loss: 0.072\n",
      "Epoch 5 loss: 0.072\n",
      "Epoch 6 loss: 0.072\n",
      "Epoch 7 loss: 0.072\n",
      "Epoch 8 loss: 0.072\n",
      "Epoch 9 loss: 0.072\n",
      "Epoch 10 loss: 0.072\n",
      "Epoch 11 loss: 0.072\n",
      "Epoch 12 loss: 0.072\n",
      "Epoch 13 loss: 0.072\n",
      "Epoch 14 loss: 0.071\n",
      "Epoch 15 loss: 0.071\n",
      "Epoch 16 loss: 0.071\n",
      "Epoch 17 loss: 0.070\n",
      "Epoch 18 loss: 0.070\n",
      "Epoch 19 loss: 0.069\n",
      "Epoch 20 loss: 0.068\n",
      "Epoch 21 loss: 0.065\n",
      "Epoch 22 loss: 0.062\n",
      "Epoch 23 loss: 0.057\n",
      "Epoch 24 loss: 0.053\n",
      "Epoch 25 loss: 0.066\n",
      "Epoch 26 loss: 0.051\n",
      "Epoch 27 loss: 0.047\n",
      "Epoch 28 loss: 0.040\n",
      "Epoch 29 loss: 0.036\n",
      "Epoch 30 loss: 0.032\n",
      "Epoch 31 loss: 0.027\n",
      "Epoch 32 loss: 0.023\n",
      "Epoch 33 loss: 0.017\n",
      "Epoch 34 loss: 0.014\n",
      "Epoch 35 loss: 0.009\n",
      "Epoch 36 loss: 0.008\n",
      "Epoch 37 loss: 0.006\n",
      "Epoch 38 loss: 0.006\n",
      "Epoch 39 loss: 0.003\n",
      "Epoch 40 loss: 0.002\n",
      "Epoch 41 loss: 0.001\n",
      "Epoch 42 loss: 0.001\n",
      "Epoch 43 loss: 0.001\n",
      "Epoch 44 loss: 0.001\n",
      "Epoch 45 loss: 0.000\n",
      "Epoch 46 loss: 0.000\n",
      "Epoch 47 loss: 0.000\n",
      "Epoch 48 loss: 0.000\n",
      "Epoch 49 loss: 0.000\n",
      "Epoch 50 loss: 0.000\n",
      "Epoch 51 loss: 0.000\n",
      "Epoch 52 loss: 0.000\n",
      "Epoch 53 loss: 0.000\n",
      "Epoch 54 loss: 0.000\n",
      "Epoch 55 loss: 0.000\n",
      "Epoch 56 loss: 0.000\n",
      "Epoch 57 loss: 0.000\n",
      "Epoch 58 loss: 0.000\n",
      "Epoch 59 loss: 0.000\n",
      "Epoch 60 loss: 0.000\n",
      "Epoch 61 loss: 0.000\n",
      "Epoch 62 loss: 0.000\n",
      "Epoch 63 loss: 0.000\n",
      "Epoch 64 loss: 0.000\n",
      "Epoch 65 loss: 0.000\n",
      "Epoch 66 loss: 0.000\n",
      "Epoch 67 loss: 0.000\n",
      "Epoch 68 loss: 0.000\n",
      "Epoch 69 loss: 0.000\n",
      "Epoch 70 loss: 0.000\n",
      "Epoch 71 loss: 0.000\n",
      "Epoch 72 loss: 0.000\n",
      "Epoch 73 loss: 0.000\n",
      "Epoch 74 loss: 0.000\n",
      "Epoch 75 loss: 0.000\n",
      "Epoch 76 loss: 0.000\n",
      "Epoch 77 loss: 0.000\n",
      "Epoch 78 loss: 0.000\n",
      "Epoch 79 loss: 0.000\n",
      "Epoch 80 loss: 0.000\n",
      "Epoch 81 loss: 0.000\n",
      "Epoch 82 loss: 0.000\n",
      "Epoch 83 loss: 0.000\n",
      "Epoch 84 loss: 0.000\n",
      "Epoch 85 loss: 0.000\n",
      "Epoch 86 loss: 0.000\n",
      "Epoch 87 loss: 0.000\n",
      "Epoch 88 loss: 0.000\n",
      "Epoch 89 loss: 0.000\n",
      "Epoch 90 loss: 0.000\n",
      "Epoch 91 loss: 0.000\n",
      "Epoch 92 loss: 0.000\n",
      "Epoch 93 loss: 0.000\n",
      "Epoch 94 loss: 0.000\n",
      "Epoch 95 loss: 0.000\n",
      "Epoch 96 loss: 0.000\n",
      "Epoch 97 loss: 0.000\n",
      "Epoch 98 loss: 0.000\n",
      "Epoch 99 loss: 0.000\n",
      "Epoch 100 loss: 0.000\n",
      "Epoch 101 loss: 0.000\n",
      "Epoch 102 loss: 0.000\n",
      "Epoch 103 loss: 0.000\n",
      "Epoch 104 loss: 0.000\n",
      "Epoch 105 loss: 0.000\n",
      "Epoch 106 loss: 0.000\n",
      "Epoch 107 loss: 0.000\n",
      "Epoch 108 loss: 0.000\n",
      "Epoch 109 loss: 0.000\n",
      "Epoch 110 loss: 0.000\n",
      "Epoch 111 loss: 0.000\n",
      "Epoch 112 loss: 0.000\n",
      "Epoch 113 loss: 0.000\n",
      "Epoch 114 loss: 0.000\n",
      "Epoch 115 loss: 0.000\n",
      "Epoch 116 loss: 0.000\n",
      "Epoch 117 loss: 0.000\n",
      "Epoch 118 loss: 0.000\n",
      "Epoch 119 loss: 0.000\n",
      "Epoch 120 loss: 0.000\n",
      "Epoch 121 loss: 0.000\n",
      "Epoch 122 loss: 0.000\n",
      "Epoch 123 loss: 0.000\n",
      "Epoch 124 loss: 0.000\n",
      "Epoch 125 loss: 0.000\n",
      "Epoch 126 loss: 0.000\n",
      "Epoch 127 loss: 0.000\n",
      "Epoch 128 loss: 0.000\n",
      "Epoch 129 loss: 0.000\n",
      "Epoch 130 loss: 0.000\n",
      "Epoch 131 loss: 0.000\n",
      "Epoch 132 loss: 0.000\n",
      "Epoch 133 loss: 0.000\n",
      "Epoch 134 loss: 0.000\n",
      "Epoch 135 loss: 0.000\n",
      "Epoch 136 loss: 0.000\n",
      "Epoch 137 loss: 0.000\n",
      "Epoch 138 loss: 0.000\n",
      "Epoch 139 loss: 0.000\n",
      "Epoch 140 loss: 0.000\n",
      "Epoch 141 loss: 0.000\n",
      "Epoch 142 loss: 0.000\n",
      "Epoch 143 loss: 0.000\n",
      "Epoch 144 loss: 0.000\n",
      "Epoch 145 loss: 0.000\n",
      "Epoch 146 loss: 0.000\n",
      "Epoch 147 loss: 0.000\n",
      "Epoch 148 loss: 0.000\n",
      "Epoch 149 loss: 0.000\n",
      "Epoch 150 loss: 0.000\n",
      "Epoch 151 loss: 0.000\n",
      "Epoch 152 loss: 0.000\n",
      "Epoch 153 loss: 0.000\n",
      "Epoch 154 loss: 0.000\n",
      "Epoch 155 loss: 0.000\n",
      "Epoch 156 loss: 0.000\n",
      "Epoch 157 loss: 0.000\n",
      "Epoch 158 loss: 0.000\n",
      "Epoch 159 loss: 0.000\n",
      "Epoch 160 loss: 0.000\n",
      "Epoch 161 loss: 0.000\n",
      "Epoch 162 loss: 0.000\n",
      "Epoch 163 loss: 0.000\n",
      "Epoch 164 loss: 0.000\n",
      "Epoch 165 loss: 0.000\n",
      "Epoch 166 loss: 0.000\n",
      "Epoch 167 loss: 0.000\n",
      "Epoch 168 loss: 0.000\n",
      "Epoch 169 loss: 0.000\n",
      "Epoch 170 loss: 0.000\n",
      "Epoch 171 loss: 0.000\n",
      "Epoch 172 loss: 0.000\n",
      "Epoch 173 loss: 0.000\n",
      "Epoch 174 loss: 0.000\n",
      "Epoch 175 loss: 0.000\n",
      "Epoch 176 loss: 0.000\n",
      "Epoch 177 loss: 0.000\n",
      "Epoch 178 loss: 0.000\n",
      "Epoch 179 loss: 0.000\n",
      "Epoch 180 loss: 0.000\n",
      "Epoch 181 loss: 0.000\n",
      "Epoch 182 loss: 0.000\n",
      "Epoch 183 loss: 0.000\n",
      "Epoch 184 loss: 0.000\n",
      "Epoch 185 loss: 0.000\n",
      "Epoch 186 loss: 0.000\n",
      "Epoch 187 loss: 0.000\n",
      "Epoch 188 loss: 0.000\n",
      "Epoch 189 loss: 0.000\n",
      "Epoch 190 loss: 0.000\n",
      "Epoch 191 loss: 0.000\n",
      "Epoch 192 loss: 0.000\n",
      "Epoch 193 loss: 0.000\n",
      "Epoch 194 loss: 0.000\n",
      "Epoch 195 loss: 0.000\n",
      "Epoch 196 loss: 0.000\n",
      "Epoch 197 loss: 0.000\n",
      "Epoch 198 loss: 0.000\n",
      "Epoch 199 loss: 0.000\n",
      "Epoch 200 loss: 0.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = ColorPredictor()\n",
    "# criterion = torch.nn.functional.binary_cross_entropy\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(200):\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, len(df), 10):\n",
    "        item_output = item_outputs[i:i+10].detach()\n",
    "        color_output = color_outputs[i:i+10].detach()\n",
    "        label = labels[i:i+10].unsqueeze(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(item_output, color_output)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print('Epoch %d loss: %.3f' % (epoch + 1, running_loss / len(df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. check_pairwise_arrays expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dylan.Tang\\Downloads\\item_color\\train_item_color.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dylan.Tang/Downloads/item_color/train_item_color.ipynb#X12sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m item_vectors \u001b[39m=\u001b[39m item_outputs\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dylan.Tang/Downloads/item_color/train_item_color.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m color_vectors \u001b[39m=\u001b[39m color_outputs\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Dylan.Tang/Downloads/item_color/train_item_color.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m cosine_similarities \u001b[39m=\u001b[39m cosine_similarity(item_vectors, color_vectors)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Dylan.Tang/Downloads/item_color/train_item_color.ipynb#X12sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(cosine_similarities)\n",
      "File \u001b[1;32mc:\\Users\\Dylan.Tang\\Anaconda3\\envs\\py10\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1351\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[39m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \n\u001b[0;32m   1319\u001b[0m \u001b[39mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1347\u001b[0m \u001b[39mkernel matrix : ndarray of shape (n_samples_X, n_samples_Y)\u001b[39;00m\n\u001b[0;32m   1348\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1349\u001b[0m \u001b[39m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1351\u001b[0m X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[0;32m   1353\u001b[0m X_normalized \u001b[39m=\u001b[39m normalize(X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1354\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n",
      "File \u001b[1;32mc:\\Users\\Dylan.Tang\\Anaconda3\\envs\\py10\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:156\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[0;32m    147\u001b[0m     X \u001b[39m=\u001b[39m Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    148\u001b[0m         X,\n\u001b[0;32m    149\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 156\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    157\u001b[0m         X,\n\u001b[0;32m    158\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    159\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    160\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    161\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    162\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m     Y \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    165\u001b[0m         Y,\n\u001b[0;32m    166\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[0;32m    171\u001b[0m     )\n\u001b[0;32m    173\u001b[0m \u001b[39mif\u001b[39;00m precomputed:\n",
      "File \u001b[1;32mc:\\Users\\Dylan.Tang\\Anaconda3\\envs\\py10\\lib\\site-packages\\sklearn\\utils\\validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n\u001b[0;32m    892\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 893\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m     )\n\u001b[0;32m    898\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    899\u001b[0m     _assert_all_finite(\n\u001b[0;32m    900\u001b[0m         array,\n\u001b[0;32m    901\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[0;32m    902\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[0;32m    903\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    904\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. check_pairwise_arrays expected <= 2."
     ]
    }
   ],
   "source": [
    "\n",
    "# 測試模型\n",
    "test_items = ['bat', 'coffee', 'sky', 'grape', 'lemon']\n",
    "test_colors = ['red', 'brown', 'blue', 'purple', 'green']\n",
    "\n",
    "for i in range(len(test_items)):\n",
    "    test_item_tokens = tokenizer(test_items[i], padding=True, truncation=True, max_length=16, return_tensors='pt')\n",
    "    test_color_tokens = tokenizer(test_colors[i], padding=True, truncation=True, max_length=8, return_tensors='pt')\n",
    "    test_item_output = bert_model(**test_item_tokens)[0].detach()\n",
    "    test_color_output = bert_model(**test_color_tokens)[0].detach()\n",
    "    test_output = model(test_item_output, test_color_output)\n",
    "    test_prediction = torch.sigmoid(test_output) > 0.5\n",
    "    \n",
    "    # 計算兩個向量的餘弦相似度\n",
    "    item_vectors = item_outputs.detach().numpy()\n",
    "    color_vectors = color_outputs.detach().numpy()\n",
    "    cosine_similarities = cosine_similarity(item_vectors, color_vectors)\n",
    "\n",
    "    print(cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.2069165 ,  0.08809706, -0.19849141, ..., -0.10356671,\n",
       "          0.08773239,  0.15185225],\n",
       "        [-0.49911833, -0.0348646 , -0.6298923 , ...,  0.4416717 ,\n",
       "          0.08368811, -0.8565332 ],\n",
       "        [ 0.89667416,  0.1536845 , -0.3115343 , ...,  0.09887315,\n",
       "         -0.693995  , -0.3875741 ],\n",
       "        [-0.05032158,  0.3333085 , -0.01176501, ...,  0.33261266,\n",
       "          0.09453274,  0.12265699],\n",
       "        [-0.29818192, -0.10951727, -0.23225972, ...,  0.30622137,\n",
       "          0.22214079,  0.06901016],\n",
       "        [-0.14767048,  0.0456373 , -0.07858583, ...,  0.23744729,\n",
       "          0.15700723,  0.11565822]],\n",
       "\n",
       "       [[-0.21428354,  0.03756715, -0.2317439 , ..., -0.08002454,\n",
       "          0.13585404,  0.01386099],\n",
       "        [-0.58986866, -0.5431918 , -0.6305308 , ...,  0.5202858 ,\n",
       "          0.4029937 , -0.4703741 ],\n",
       "        [ 0.93898654,  0.16755196, -0.26549673, ...,  0.07251855,\n",
       "         -0.77950716, -0.35671908],\n",
       "        [-0.3460751 ,  0.03673025, -0.03448339, ...,  0.12769046,\n",
       "          0.21708108,  0.19119972],\n",
       "        [-0.46354973, -0.261874  , -0.09532602, ...,  0.20331159,\n",
       "          0.27072757,  0.17460364],\n",
       "        [-0.3290563 , -0.18144813, -0.04436118, ...,  0.16551004,\n",
       "          0.22176778,  0.14498718]],\n",
       "\n",
       "       [[-0.01271448,  0.2726097 , -0.00710195, ..., -0.10088836,\n",
       "          0.11465263,  0.08244526],\n",
       "        [-0.16929068, -0.14532897,  0.30905887, ...,  0.0983962 ,\n",
       "          0.6160053 , -0.72286266],\n",
       "        [ 1.1996294 ,  0.19761598, -0.40481114, ...,  0.07661606,\n",
       "         -0.7194798 , -0.23430595],\n",
       "        [-0.06933324,  0.3464739 ,  0.55492055, ...,  0.17356475,\n",
       "          0.3979081 ,  0.11684779],\n",
       "        [-0.16121008,  0.02601282,  0.4631925 , ...,  0.30148402,\n",
       "          0.42241558,  0.02442243],\n",
       "        [-0.0502724 ,  0.11430051,  0.41832083, ...,  0.26496243,\n",
       "          0.38486272,  0.15947676]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.32980517,  0.15783447, -0.13565804, ..., -0.13235466,\n",
       "          0.30170983,  0.2302763 ],\n",
       "        [-0.10924622, -0.06655976, -0.25455365, ...,  0.46797675,\n",
       "          0.22084016, -0.18754026],\n",
       "        [ 0.865013  ,  0.12257989, -0.35349214, ...,  0.09384256,\n",
       "         -0.748564  , -0.22489224],\n",
       "        [-0.27313215,  0.02219087,  0.10914749, ...,  0.07182255,\n",
       "          0.31351444,  0.33600277],\n",
       "        [-0.39801994, -0.2555997 ,  0.00383963, ...,  0.18362603,\n",
       "          0.3093803 ,  0.33713   ],\n",
       "        [-0.27328834, -0.1443136 ,  0.09082338, ...,  0.14503771,\n",
       "          0.3048715 ,  0.3304374 ]],\n",
       "\n",
       "       [[-0.66826123,  0.36209103, -0.3588369 , ...,  0.07667611,\n",
       "          0.30709025,  0.3577245 ],\n",
       "        [-0.04654137, -0.0133493 , -0.3903935 , ...,  0.4131601 ,\n",
       "          0.28153735, -0.157058  ],\n",
       "        [-0.9041799 , -0.26189467, -0.9141018 , ...,  0.41487023,\n",
       "          0.01290255, -0.22390147],\n",
       "        [ 0.74687904,  0.0577366 , -0.3735815 , ...,  0.10921087,\n",
       "         -0.5640124 , -0.3128933 ],\n",
       "        [-0.59030807, -0.2399934 , -0.25387198, ...,  0.04427682,\n",
       "          0.07617149,  0.05618963],\n",
       "        [-0.5876098 , -0.40716624, -0.3971916 , ...,  0.15031035,\n",
       "          0.12889123,  0.06950622]],\n",
       "\n",
       "       [[-0.7759334 ,  0.24013191, -0.37029827, ...,  0.20234516,\n",
       "          0.41200295,  0.3822095 ],\n",
       "        [ 0.20343447,  0.18924767, -0.6766773 , ...,  0.11946496,\n",
       "          0.066623  , -0.256849  ],\n",
       "        [ 0.5576119 ,  0.25228435,  0.28342307, ...,  0.65612805,\n",
       "          0.6509919 , -0.561733  ],\n",
       "        [-0.61942834, -0.03685597, -1.3399421 , ...,  0.45294407,\n",
       "         -0.29056475, -0.6437291 ],\n",
       "        [ 0.8385612 , -0.03078125, -0.38672838, ...,  0.12293089,\n",
       "         -0.6830895 , -0.34939906],\n",
       "        [-0.5145049 , -0.02896275, -0.6269266 , ...,  0.29044497,\n",
       "          0.20056304,  0.01182169]]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\Dylan.Tang/.cache\\torch\\sentence_transformers\\bert-base-uncased. Creating a new one with MEAN pooling.\n",
      "Some weights of the model checkpoint at C:\\Users\\Dylan.Tang/.cache\\torch\\sentence_transformers\\bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "sentence_model = SentenceTransformer('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree: green (incorrect)\n",
      "兩個向量之間的餘弦相似度： 0.7305856\n",
      "watercress: pink (incorrect)\n",
      "兩個向量之間的餘弦相似度： 0.58263755\n",
      "black tea: green (incorrect)\n",
      "兩個向量之間的餘弦相似度： 0.7028487\n",
      "grape: green (incorrect)\n",
      "兩個向量之間的餘弦相似度： 0.71846133\n",
      "white board: blue (incorrect)\n",
      "兩個向量之間的餘弦相似度： 0.752831\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 測試模型\n",
    "test_items = ['tree', 'watercress', 'black tea', 'grape', 'white board']\n",
    "test_colors = ['green', 'pink', 'green', 'green', 'blue']\n",
    "\n",
    "for i in range(len(test_items)):\n",
    "    test_item_tokens = tokenizer(test_items[i], padding=True, truncation=True, max_length=16, return_tensors='pt')\n",
    "    test_color_tokens = tokenizer(test_colors[i], padding=True, truncation=True, max_length=8, return_tensors='pt')\n",
    "    test_item_output = bert_model(**test_item_tokens)[0]\n",
    "    test_color_output = bert_model(**test_color_tokens)[0]\n",
    "    test_output = model(test_item_output, test_color_output)\n",
    "    test_prediction = torch.sigmoid(test_output) > 0.5\n",
    "\n",
    "    # 計算兩個向量的餘弦相似度\n",
    "    vector_a = sentence_model.encode(test_items[i])\n",
    "    vector_b = sentence_model.encode(test_colors[i])\n",
    "    cosine_similarity = np.dot(vector_a, vector_b) / (np.linalg.norm(vector_a) * np.linalg.norm(vector_b))\n",
    "\n",
    "\n",
    "    \n",
    "    print('%s: %s (%s)' % (test_items[i], test_colors[i], 'correct' if test_prediction.item() else 'incorrect'))\n",
    "    print(\"兩個向量之間的餘弦相似度：\", cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
